Skipping features from features/Science.type.rachel-ngram
Reading features from features/Science.type.rachel-topic
Reading features from features/Science.type.hal-rf
Reading features from features/Science.type.hal-flow
Reading features from features/Science.type.hal-ppl
Skipping features from features/Science.token.jags-psd-comp-real
Skipping features from features/Science.token.hal-ppl
Skipping features from features/Science.token.anni-context-percent
Skipping features from features/Science.token.anni-context-pos
Skipping features from features/Science.token.jags-psd
Skipping features from features/Science.token.jags-psd-real
Skipping features from features/Science.token.jags-local-psd
Skipping features from features/Science.token.jags-local-psd-real
warning: data included 4 unseen french phrases: frottement galaxies scalaire spectres
Read 8293 examples (2018 positive and 6275 negative, which is 24.3% positive)
===== FOLD 1 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000461936437546194 0.00138580931263858 +0.000461936437546194
................................................................................................................
dev  score = 0.846733547351525 on pass 15 with config --l2 0.000923872875092388
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 15 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=0.vwmodel --args --l2 0.000923872875092388 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
.............................................. 
0.264150943396226 0.318181818181818 0.225806451612903 <-macroFPR-|-microFPR-> 0.226430976430976 0.694444444444445 0.5

===== FOLD 2 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000489188924762743 0.00146756677428823 +0.000489188924762743
fold 0 score = 0.697328629032258
......................................................................................................................................................................
dev  score = 0.861271421370968 on pass 10 with config --l2 0.00146756677428823
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 10 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=1.vwmodel --args --l2 0.00146756677428823 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................. 
0 1 0 <-macroFPR-|-microFPR-> 0 1 0

===== FOLD 3 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000472679145396105 0.00141803743618832 +0.000472679145396105
fold 1 score = 0.84542937399679
......................................................................................................................................................................
dev  score = 0.95788160111913 on pass 7 with config --l2 0.00094535829079221
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 7 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=2.vwmodel --args --l2 0.00094535829079221 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................. 
0.521739130434783 0.561151079136691 0.4875 <-macroFPR-|-microFPR-> 0.479353241781462 0.760281385281385 0.681818181818182

===== FOLD 4 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000511482788604163 0.00153444836581249 +0.000511482788604163
fold 2 score = 0.818006552419355
......................................................................................................................................................................
dev  score = 0.934580351333767 on pass 13 with config --l2 0.000511482788604163
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 13 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=3.vwmodel --args --l2 0.000511482788604163 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
.............................................. 
0.837209302325581 0.931034482758621 0.76056338028169 <-macroFPR-|-microFPR-> 0.378439153439153 0.896296296296296 0.444444444444444

===== FOLD 5 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000526177321757432 0.0015785319652723 +0.000526177321757432
fold 3 score = 0.963612374018377
......................................................................................................................................................................
dev  score = 0.846746432735551 on pass 15 with config --l2 0.000526177321757432
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 15 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=4.vwmodel --args --l2 0.000526177321757432 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
.............................................. 
0.365535248041775 0.752688172043011 0.241379310344828 <-macroFPR-|-microFPR-> 0.332063955058607 0.953216374269006 0.363636363636364

===== FOLD 6 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000458379171250458 0.00137513751375138 +0.000458379171250458
fold 4 score = 0.935923686325539
......................................................................................................................................................................
dev  score = 0.876806115591398 on pass 14 with config --l2 0.00137513751375137
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 14 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=5.vwmodel --args --l2 0.00137513751375137 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
.............................................. 
0.12807881773399 0.764705882352941 0.0698924731182796 <-macroFPR-|-microFPR-> 0.122655122655123 0.968253968253968 0.142857142857143

===== FOLD 7 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000439348007556786 0.00131804402267036 +0.000439348007556786
fold 5 score = 0.837057909055577
......................................................................................................................................................................
dev  score = 0.699388623072834 on pass 9 with config --l2 0.00131804402267036
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 9 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=6.vwmodel --args --l2 0.00131804402267036 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................. 
0 1 0 <-macroFPR-|-microFPR-> 0 1 0

===== FOLD 8 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000437962597994131 0.00131388779398239 +0.000437962597994131
fold 6 score = 0.876806115591398
................................................................................................................
dev  score = 0.736709770114943 on pass 3 with config --l2 0.000437962597994131
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 3 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=7.vwmodel --args --l2 0.000437962597994131 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................ 
0.510869565217391 0.635135135135135 0.427272727272727 <-macroFPR-|-microFPR-> 0.285667293233083 0.891287878787879 0.375

===== FOLD 9 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.00047328316531781 0.00141984949595343 +0.00047328316531781
fold 7 score = 0.636390217969165
................................................................................................................
dev  score = 0.871249791074712 on pass 6 with config --l2 0.00094656633063562
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 6 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=8.vwmodel --args --l2 0.00094656633063562 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................. 
0.0350877192982456 1 0.0178571428571429 <-macroFPR-|-microFPR-> 0.0833333333333333 1 0.0833333333333333

===== FOLD 10 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000479754365764728 0.00143926309729419 +0.000479754365764728
fold 8 score = 0.749794745484401
......................................................................................................................................................................
dev  score = 0.891736132551199 on pass 3 with config --l2 0.000959508731529456
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 3 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=9.vwmodel --args --l2 0.000959508731529456 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
........................................... 
0.627956989247312 0.672811059907834 0.588709677419355 <-macroFPR-|-microFPR-> 0.391535472853302 0.672587782587783 0.688888888888889

===== FOLD 11 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000435331504941013 0.00130599451482304 +0.000435331504941013
fold 9 score = 0.856831334614742
......................................................................................................................................................................
dev  score = 0.835526315789474 on pass 12 with config --l2 0.000435331504941013
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 12 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=10.vwmodel --args --l2 0.000435331504941013 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
.............................................. 
0.753623188405797 0.88135593220339 0.658227848101266 <-macroFPR-|-microFPR-> 0.376271876271876 0.877838827838828 0.461538461538462

===== FOLD 12 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000428393951077411 0.00128518185323223 +0.000428393951077411
fold 10 score = 0.891273026654317
................................................................................................................
dev  score = 0.750067132116004 on pass 2 with config --l2 0.000428393951077411
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 2 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=11.vwmodel --args --l2 0.000428393951077411 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
........................................... 
0.157303370786517 0.538461538461538 0.0921052631578947 <-macroFPR-|-microFPR-> 0.2 0.911111111111111 0.266666666666667

===== FOLD 13 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000454380225372592 0.00136314067611778 +0.000454380225372592
fold 11 score = 0.810554311310191
......................................................................................................................................................................
dev  score = 0.783710854363028 on pass 9 with config --l2 0.000454380225372592
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 9 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=12.vwmodel --args --l2 0.000454380225372592 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................. 
0.352941176470588 0.631578947368421 0.244897959183673 <-macroFPR-|-microFPR-> 0.186683006535948 0.9 0.25

===== FOLD 14 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000454442172233583 0.00136332651670075 +0.000454442172233583
fold 12 score = 0.747516111707841
......................................................................................................................................................................
dev  score = 0.648792850473523 on pass 3 with config --l2 0.000454442172233583
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 3 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=13.vwmodel --args --l2 0.000454442172233583 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................ 
0.523943661971831 0.543859649122807 0.505434782608696 <-macroFPR-|-microFPR-> 0.266231989847907 0.655882352941176 0.588235294117647

===== FOLD 15 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000425985090521832 0.0012779552715655 +0.000425985090521832
fold 13 score = 0.78191984645789
......................................................................................................................................................................
dev  score = 0.742786069651741 on pass 3 with config --l2 0.000851970181043664
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 3 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=14.vwmodel --args --l2 0.000851970181043664 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................ 
0.208955223880597 0.388888888888889 0.142857142857143 <-macroFPR-|-microFPR-> 0.261538461538462 0.83974358974359 0.384615384615385

===== FOLD 16 / 16 =====
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.train --dev classifiers/abl8.Science.remove=type.rachel-ngram.dev --eval auroc --logistic --passes 15 --search --l2 0.000428834855697071 0.00128650456709121 +0.000428834855697071
fold 14 score = 0.525676937441643
................................................................................................................
dev  score = 0.725176411290323 on pass 4 with config --l2 0.000857669711394142
Running: bin/vwx --vw /home/hal/projects/vowpal_wabbit/vowpalwabbit/vw -d classifiers/abl8.Science.remove=type.rachel-ngram.traindev --dev classifiers/abl8.Science.remove=type.rachel-ngram.test --eval auroc --logistic --passes 4 --noearlystop --readable classifiers/abl8.Science.remove=type.rachel-ngram.fold=15.vwmodel --args --l2 0.000857669711394142 -p classifiers/abl8.Science.remove=type.rachel-ngram.test.predictions
............................................ 
0.105263157894737 0.363636363636364 0.0615384615384615 <-macroFPR-|-microFPR-> 0.13903743315508 0.954248366013072 0.176470588235294

fold 15 score = 0.701339456563337
Average score 0.792216289290177 (std 0.109973293684109)
Average FPR: 0.337041093444086 0.686468059324841 0.282752663772129 <-macroFPR-|-microFPR-> 0.233077582258395 0.873449523598034 0.337969046884488
Std.dev FPR: 0.259620881527622 0.22296263221157 0.245192142331333 <-macroFPR-|-microFPR-> 0.136306066529233 0.1136259694352 0.213795327234551
